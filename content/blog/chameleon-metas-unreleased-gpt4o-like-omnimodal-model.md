---
title: "Chameleon: Meta's (unreleased) GPT4o-like Omnimodal Model"
date: "2024-05-17T20:46:44.000Z"
description: "**Meta AI FAIR** introduced **Chameleon**, a new multimodal model family with **7B** and **34B** parameter versions trained on **10T tokens** of interleaved tex..."
original_link: "https://news.smol.ai/issues/24-05-17-ainews-chameleon-metas-unreleased-gpt4o-like-omnimodal-model/"
---

**Meta AI FAIR** introduced **Chameleon**, a new multimodal model family with **7B** and **34B** parameter versions trained on **10T tokens** of interleaved text and image data enabling "early fusion" multimodality that can natively output any modality. While reasoning benchmarks are modest, its "omnimodality" approach competes well with pre-GPT4o multimodal models. **OpenAI** launched **GPT-4o**, a model excelling in benchmarks like MMLU and coding tasks, with strong multimodal capabilities but some regression in ELO scores and hallucination issues. **Google DeepMind** announced **Gemini 1.5 Flash**, a small model with **1M context window** and flash performance, highlighting convergence trends between OpenAI and Google models. **Anthropic** updated **Claude 3** with streaming support, forced tool use, and vision tool integration for multimodal knowledge extraction. OpenAI also partnered with Reddit, raising industry attention.

[Read original post](https://news.smol.ai/issues/24-05-17-ainews-chameleon-metas-unreleased-gpt4o-like-omnimodal-model/)
