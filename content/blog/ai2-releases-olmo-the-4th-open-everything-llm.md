---
title: "AI2 releases OLMo - the 4th open-everything LLM"
date: "2024-02-03T03:35:10.000Z"
description: "**AI2** is gaining attention in 2024 with its new **OLMo** models, including 1B and 7B sizes and a 65B model forthcoming, emphasizing open and reproducible rese..."
original_link: "https://news.smol.ai/issues/24-02-02-ainews-ai2-releases-olmo-the-4th-open-everything-llm/"
---

**AI2** is gaining attention in 2024 with its new **OLMo** models, including 1B and 7B sizes and a 65B model forthcoming, emphasizing open and reproducible research akin to **Pythia**. The **Miqu-70B** model, especially the Mistral Medium variant, is praised for self-correction and speed optimizations. Discussions in **TheBloke** Discord covered programming language preferences, VRAM constraints for large models, and fine-tuning experiments with **Distilbert-base-uncased**. The **Mistral** Discord highlighted challenges in the **GPU shortage** affecting semiconductor production involving **TSMC**, **ASML**, and **Zeiss**, debates on open-source versus proprietary models, and fine-tuning techniques including **LoRA** for low-resource languages. Community insights also touched on embedding chunking strategies and JSON output improvements.

[Read original post](https://news.smol.ai/issues/24-02-02-ainews-ai2-releases-olmo-the-4th-open-everything-llm/)
