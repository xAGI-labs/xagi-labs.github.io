---
title: "GPT4Turbo A/B Test: gpt-4-1106-preview"
date: "2024-01-26T22:07:42.000Z"
description: "**OpenAI** released a new **GPT-4 Turbo** version, prompting a natural experiment in summarization comparing the November 2023 and January 2024 versions. The **..."
original_link: "https://news.smol.ai/issues/24-01-26-ainews-gpt4turbo-ab-test-gpt-4-1106-preview/"
---

**OpenAI** released a new **GPT-4 Turbo** version, prompting a natural experiment in summarization comparing the November 2023 and January 2024 versions. The **TheBloke** Discord discussed troubleshooting model loading errors with **OpenHermes-2.5-Mistral-7B-4.0bpw** and **exllamav2**, debates on **RHEL** in ML, dataset generation for understanding GPT flaws, and running LLMs like **Llama** and **Mistral** on consoles. **LangChain** fine-tuning challenges for **Llama2** were also noted. The **OpenAI** Discord highlighted **GPT-4** speed inconsistencies, API vs web performance, prompt engineering with **GPT-3.5** and **GPT-4 Turbo**, and **DALL-E** typo issues in image text. Discussions included NLP tools like \*semantic-text-splitter\* and collaboration concerns with **GPT-4 Vision** on **Azure**. The **Nous Research AI** Discord focused on extending context windows with **Mistral instruct v0.2**, **MistralLite**, and **LLaMA-2-7B-Chat** achieving 16,384 token context, plus alternatives like **SelfExtend** for context extension without fine-tuning. The societal impact of AI technology was also considered.

[Read original post](https://news.smol.ai/issues/24-01-26-ainews-gpt4turbo-ab-test-gpt-4-1106-preview/)
