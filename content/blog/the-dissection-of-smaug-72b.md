---
title: "The Dissection of Smaug (72B)"
date: "2024-02-13T01:40:29.000Z"
description: "**Abacus AI** launched **Smaug 72B**, a large finetune of **Qwen 1.0**, which remains unchallenged on the **Hugging Face Open LLM Leaderboard** despite skeptici..."
original_link: "https://news.smol.ai/issues/24-02-12-ainews-the-dissection-of-smaug-72b/"
---

**Abacus AI** launched **Smaug 72B**, a large finetune of **Qwen 1.0**, which remains unchallenged on the **Hugging Face Open LLM Leaderboard** despite skepticism from **Nous Research**. **LAION** introduced a local voice assistant model named **Bud-E** with a notable demo. The **TheBloke Discord** community discussed model performance trade-offs between large models like **GPT-4** and smaller quantized models, fine-tuning techniques using datasets like **WizardLM\_evol\_instruct\_V2\_196k** and **OpenHermes-2.5**, and challenges in web UI development and model merging involving **Mistral-7b** and **MiquMaid**. The **LM Studio Discord** highlighted issues with model conversion from PyTorch to gguf, hardware setups involving **Intel Xeon CPUs** and **Nvidia P40 GPUs**, privacy concerns, and limitations in image generation and web UI availability.

[Read original post](https://news.smol.ai/issues/24-02-12-ainews-the-dissection-of-smaug-72b/)
