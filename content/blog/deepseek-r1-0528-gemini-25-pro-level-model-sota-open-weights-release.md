---
title: "DeepSeek-R1-0528 - Gemini 2.5 Pro-level model, SOTA Open Weights release"
date: "2025-05-29T05:44:39.000Z"
description: "**DeepSeek R1-0528** marks a significant upgrade, closing the gap with proprietary models like **Gemini 2.5 Pro** and surpassing benchmarks from **Anthropic**, ..."
original_link: "https://news.smol.ai/issues/25-05-29-deepseek-r1-0528/"
---

**DeepSeek R1-0528** marks a significant upgrade, closing the gap with proprietary models like **Gemini 2.5 Pro** and surpassing benchmarks from **Anthropic**, **Meta**, **NVIDIA**, and **Alibaba**. This Chinese open-weights model leads in several AI benchmarks, driven by reinforcement learning post-training rather than architecture changes, and demonstrates increased reasoning token usage (23K tokens per question). The China-US AI race intensifies as Chinese labs accelerate innovation through transparency and open research culture. Key benchmarks include **AIME 2024**, **LiveCodeBench**, and **GPQA Diamond**.

[Read original post](https://news.smol.ai/issues/25-05-29-deepseek-r1-0528/)
