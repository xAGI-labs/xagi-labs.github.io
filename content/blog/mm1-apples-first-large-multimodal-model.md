---
title: "MM1: Apple's first Large Multimodal Model"
date: "2024-03-15T23:34:51.000Z"
description: "**Apple** announced the **MM1** multimodal LLM family with up to **30B parameters**, claiming performance comparable to **Gemini-1** and beating larger older mo..."
original_link: "https://news.smol.ai/issues/24-03-15-ainews-mm1-apples-first-large-multimodal-model/"
---

**Apple** announced the **MM1** multimodal LLM family with up to **30B parameters**, claiming performance comparable to **Gemini-1** and beating larger older models on VQA benchmarks. The paper targets researchers and hints at applications in embodied agents and business/education. **Yann LeCun** emphasized that human-level AI requires understanding the physical world, memory, reasoning, and hierarchical planning, while **Franois Chollet** cautioned that NLP is far from solved despite LLM advances. **Cohere** released **Command-R**, a model for Retrieval Augmented Generation, and **Anthropic** highlighted the **Claude 3** family (Opus, Sonnet, Haiku) for various application needs. Open-source hardware **DexCap** enables dexterous robot manipulation data collection affordably. Tools like **CopilotKit** simplify AI integration into React apps, and migration to **Keras 3** with JAX backend offers faster training. New projects improve reranking for retrieval and add financial agents to **LangChain**. The content includes insights on AI progress, new models, open-source tools, and frameworks.

[Read original post](https://news.smol.ai/issues/24-03-15-ainews-mm1-apples-first-large-multimodal-model/)
