---
title: "Gemma 2 2B + Scope + Shield"
date: "2024-08-01T01:33:32.000Z"
description: "**Gemma 2B**, a 2 billion parameter model trained on **2 trillion tokens** and distilled from a larger unnamed LLM, has been released by **Google DeepMind** and..."
original_link: "https://news.smol.ai/issues/24-07-31-ainews-gemma-2-2b-scope-shield/"
---

**Gemma 2B**, a 2 billion parameter model trained on **2 trillion tokens** and distilled from a larger unnamed LLM, has been released by **Google DeepMind** and shows strong leaderboard performance despite weaknesses in math. The Gemma series, including 9B and 27B models, has gained popularity since its June release. The team also released 400 SAEs for interpretability, inspired by **Anthropic**'s research. A finetuned classifier called ShieldGemma outperforms Meta's LlamaGuard in harm detection. Meanwhile, **Meta AI** announced **Llama-3.1-405B** reaching #3 on the Overall Arena leaderboard, and released **SAM 2**, a video and image segmentation model with significant speed improvements. **OpenAI** is rolling out an advanced Voice Mode to Plus users. **Perplexity AI** launched a Publishers Program with major media partners and a status page. **NVIDIA** introduced Project GR00T for scaling robot data using Apple Vision Pro and generative simulation. Interest in quantization for compressing LLMs is growing, and LLM-as-a-Judge implementations from Vicuna, AlpacaEval, and G-Eval highlight the effectiveness of simple prompts and domain-specific evaluation.

[Read original post](https://news.smol.ai/issues/24-07-31-ainews-gemma-2-2b-scope-shield/)
