---
title: "12/13/2023 SOLAR10.7B upstages Mistral7B?"
date: "2023-12-13T23:29:29.000Z"
description: "**Upstage** released the **SOLAR-10.7B** model, which uses a novel Depth Up-Scaling technique built on the **llama-2** architecture and integrates **mistral-7b*..."
original_link: "https://news.smol.ai/issues/23-12-13-ainews-12132023-solar107b-upstages-mistral7b/"
---

**Upstage** released the **SOLAR-10.7B** model, which uses a novel Depth Up-Scaling technique built on the **llama-2** architecture and integrates **mistral-7b** weights, followed by continued pre-training. The **Nous** community finds it promising but not exceptional. Additionally, weights for the **phi-2** base model were released, trained on **1.4 trillion tokens** including synthetic texts created by GPT-3 and filtered by GPT-4, using **96 A100 GPUs** over 14 days. On **OpenAI's** Discord, users discussed challenges with various **GPT** models, including incoherent outputs, API usage limitations, and issues with **GPT-4 Vision API**. Conversations also covered understanding **AGI** and **ASI**, concerns about OpenAI's partnership with Axel Springer, and pricing changes for GPT Plus. Discussions included the **Gemini** chat model integrated into Bard and comparisons with GPT-4 performance.

[Read original post](https://news.smol.ai/issues/23-12-13-ainews-12132023-solar107b-upstages-mistral7b/)
