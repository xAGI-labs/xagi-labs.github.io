---
title: "OpenAI Voice Mode Can See Now - After Gemini Does"
date: "2024-12-18T09:46:07.000Z"
description: "**OpenAI** launched **Realtime Video** shortly after **Gemini**, which led to less impact due to Gemini's earlier arrival with lower cost and fewer rate limits...."
original_link: "https://news.smol.ai/issues/24-12-18-ainews-openai-voice-mode-can-see-now-after-gemini-does/"
---

**OpenAI** launched **Realtime Video** shortly after **Gemini**, which led to less impact due to Gemini's earlier arrival with lower cost and fewer rate limits. **Google DeepMind** released **Gemini 2.0 Flash** featuring enhanced multimodal capabilities and real-time streaming. **Anthropic** introduced **Clio**, a system analyzing real-world usage of **Claude** models. Together Computing acquired CodeSandbox to launch a code interpreter tool. Discussions highlighted **Meta's Llama 3.3-70B** for its advanced roleplay and prompt handling abilities, outperforming models like **Mistral Large** and **GPT-4o** in expressiveness and censorship. The AI community also engaged in humorous takes on AI outages and model competition, with **ChatGPT** adding a Santa mode for holiday interactions. \*"Anthropic is capturing the developer ecosystem, Gemini has AI enthusiast mindshare, ChatGPT reigns over AI dabblers"\* was a noted observation from the community.

[Read original post](https://news.smol.ai/issues/24-12-18-ainews-openai-voice-mode-can-see-now-after-gemini-does/)
