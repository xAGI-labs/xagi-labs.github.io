---
title: "Pixtral 12B: Mistral beats Llama to Multimodality"
date: "2024-09-12T00:30:22.000Z"
description: "**Mistral AI** released **Pixtral 12B**, an open-weights **vision-language model** with a **Mistral Nemo 12B** text backbone and a 400M vision adapter, featurin..."
original_link: "https://news.smol.ai/issues/24-09-11-ainews-pixtral-12b-mistral-beats-llama-to-multimodality/"
---

**Mistral AI** released **Pixtral 12B**, an open-weights **vision-language model** with a **Mistral Nemo 12B** text backbone and a 400M vision adapter, featuring a large vocabulary of **131,072 tokens** and support for **1024x1024 pixel images**. This release notably beat **Meta AI** in launching an open multimodal model. At the Mistral AI Summit, architecture details and benchmark performances were shared, showing strong OCR and screen understanding capabilities. Additionally, **Arcee AI** announced **SuperNova**, a distilled **Llama 3.1 70B & 8B** model outperforming Meta's Llama 3.1 70B instruct on benchmarks. **DeepSeek** released **DeepSeek-V2.5**, scoring **89 on HumanEval**, surpassing **GPT-4-Turbo**, Opus, and Llama 3.1 in coding tasks. **OpenAI** plans to release **Strawberry** as part of ChatGPT soon, though its capabilities are debated. **Anthropic** introduced Workspaces for managing multiple Claude deployments with enhanced access controls.

[Read original post](https://news.smol.ai/issues/24-09-11-ainews-pixtral-12b-mistral-beats-llama-to-multimodality/)
