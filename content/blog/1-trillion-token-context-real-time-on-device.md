---
title: "1 TRILLION token context, real time, on device?"
date: "2024-05-29T23:01:07.000Z"
description: "**Cartesia**, a startup specializing in **state space models (SSMs)**, launched a low latency voice model outperforming transformer-based models with **20% lowe..."
original_link: "https://news.smol.ai/issues/24-05-29-ainews-1-trillion-token-context-real-time-on-device/"
---

**Cartesia**, a startup specializing in **state space models (SSMs)**, launched a low latency voice model outperforming transformer-based models with **20% lower perplexity**, **2x lower word error**, and **1 point higher NISQA quality**. This breakthrough highlights the potential for models that can continuously process and reason over massive streams of multimodal data (text, audio, video) with a **trillion token context window** on-device. The news also covers recent AI developments including **Mistral's Codestral weights release**, **Schedule Free optimizers** paper release, and **Scale AI's** new elo-style eval leaderboards. Additionally, a debate between **yann-lecun** and **elon-musk** on the importance of publishing AI research versus engineering achievements was noted. The **Gemini 1.5 Pro/Advanced** models were mentioned for their strong performance.

[Read original post](https://news.smol.ai/issues/24-05-29-ainews-1-trillion-token-context-real-time-on-device/)
