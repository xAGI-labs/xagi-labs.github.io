---
title: "AI gets Memory"
date: "2024-02-15T00:47:59.000Z"
description: "**AI Discords** analysis covered **20 guilds**, **312 channels**, and **6901 messages**. The report highlights the divergence of RAG style operations for contex..."
original_link: "https://news.smol.ai/issues/24-02-14-ainews-ai-gets-memory/"
---

**AI Discords** analysis covered **20 guilds**, **312 channels**, and **6901 messages**. The report highlights the divergence of RAG style operations for context and memory, with implementations like **MemGPT** rolling out in **ChatGPT** and **LangChain**. The **TheBloke Discord** discussed **open-source large language models** such as the **Large World Model** with contexts up to **1 million tokens**, and the **Cohere aya model** supporting **101 languages**. Roleplay-focused models like **MiquMaid-v2-70B** were noted for performance improvements with enhanced hardware. Finetuning techniques like **Sequential Fine-Tuning (SFT)** and **Direct Preference Optimization (DPO)** were explained, with tools like **Unsloth AI's apply\_chat\_template** preferred over Alpaca. Integration of JavaScript and Python via **JSPyBridge** in the **SillyTavern** project was also discussed. Training challenges with **Mixtral 8x7b qlora** versus **Mistral 7b** were noted. The **LM Studio Discord** focused on hardware limitations affecting large model loading, medical LLMs like **medAlpaca**, and hardware discussions around GPU upgrades and overclocking. Anticipation for **IQ3\_XSS** 1.5 bit quantization support in LM Studio was expressed.

[Read original post](https://news.smol.ai/issues/24-02-14-ainews-ai-gets-memory/)
