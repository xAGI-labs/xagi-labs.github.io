---
title: "GPT-5 Codex launch and OpenAI's quiet rise in Agentic Coding"
date: "2025-09-15T05:44:39.000Z"
description: "**OpenAI** released **GPT-5-Codex**, an agentic coding model optimized for long-running software engineering tasks with dynamic task-adaptive thinking, multi-ho..."
original_link: "https://news.smol.ai/issues/25-09-15-gpt5-codex/"
---

**OpenAI** released **GPT-5-Codex**, an agentic coding model optimized for long-running software engineering tasks with dynamic task-adaptive thinking, multi-hour autonomy, and improved code quality. It achieves 51% accuracy on an unreleased large refactor benchmark and integrates deeply with developer tools like Xcode. Meanwhile, **Alibaba** launched **Qwen3-Next-80B**, a hybrid MoE model with native long-context support (262k tokens, extensible to 1M+), targeting efficient reasoning and repository-scale code analysis, supported by **Together AI** and **NVIDIA** with CUDA-accelerated attention. The trend towards hybrid SSM + MoE architectures is noted, emphasizing efficiency and scaling in China and US training regimes. Community discussions highlight the importance of variable compute and routing for inference efficiency and quality.

[Read original post](https://news.smol.ai/issues/25-09-15-gpt5-codex/)
