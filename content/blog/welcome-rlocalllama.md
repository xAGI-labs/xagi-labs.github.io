---
title: "Welcome /r/LocalLlama!"
date: "2024-03-21T23:33:53.000Z"
description: "**Sakana** released a paper on evolutionary model merging. **OpenInterpreter** launched their **O1 devkit**. Discussions highlight **Claude Haiku**'s underrated..."
original_link: "https://news.smol.ai/issues/24-03-21-ainews-welcome-rlocalllama/"
---

**Sakana** released a paper on evolutionary model merging. **OpenInterpreter** launched their **O1 devkit**. Discussions highlight **Claude Haiku**'s underrated performance with 10-shot examples. On **Reddit's IPO**, AINews introduces Reddit summaries starting with /r/LocalLlama, covering upcoming subreddits like r/machinelearning and r/openai. **Aether Research** released **Cerebrum 8x7b** based on **Mixtral**, matching **GPT-3.5 Turbo** and **Gemini Pro** on reasoning tasks, setting a new open-source reasoning SOTA. **Moistral 11B v1** finetuned model from Cream-Phi-2 creators was released. A creative writing benchmark uses **Claude Opus** as judge. Hobbyists explore **1.58 BitNet** ternary quantization and **1-bit LLMs** training. Nvidia's **Blackwell (h200)** chip supports **FP4 precision** quantization. **LMDeploy v0.2.6+** enables efficient vision-language model deployment with models like **Qwen-VL-Chat**. Users seek GUIs for LLM APIs with plugin and RAG support. Pipelines for synthetic training data generation and fine-tuning language models for chat are discussed.

[Read original post](https://news.smol.ai/issues/24-03-21-ainews-welcome-rlocalllama/)
