---
title: "Mini, Nemo, Turbo, Lite - Smol models go brrr (GPT4o version)"
date: "2024-07-19T00:00:39.000Z"
description: "**GPT-4o-mini** launches with a **99% price reduction** compared to text-davinci-003, offering **3.5% the price of GPT-4o** and matching Opus-level benchmarks. ..."
original_link: "https://news.smol.ai/issues/24-07-18-ainews-mini-nemo-turbo-lite-smol-models-go-brrr-gpt4o-version/"
---

**GPT-4o-mini** launches with a **99% price reduction** compared to text-davinci-003, offering **3.5% the price of GPT-4o** and matching Opus-level benchmarks. It supports **16k output tokens**, is faster than previous models, and will soon support **text, image, video, and audio inputs and outputs**. **Mistral Nemo**, a **12B parameter model** developed with **Nvidia**, features a **128k token context window**, FP8 checkpoint, and strong benchmark performance. **Together Lite and Turbo** offer fp8/int4 quantizations of **Llama 3** with up to **4x throughput** and significantly reduced costs. **DeepSeek V2** is now open-sourced. Upcoming releases include at least **5 unreleased models** and **Llama 4** leaks ahead of ICML 2024.

[Read original post](https://news.smol.ai/issues/24-07-18-ainews-mini-nemo-turbo-lite-smol-models-go-brrr-gpt4o-version/)
