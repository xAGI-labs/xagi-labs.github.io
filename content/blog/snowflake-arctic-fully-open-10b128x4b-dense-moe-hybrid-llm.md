---
title: "Snowflake Arctic: Fully Open 10B+128x4B Dense-MoE Hybrid LLM"
date: "2024-04-26T01:33:53.000Z"
description: "**Snowflake Arctic** is a notable new foundation language model released under Apache 2.0, claiming superiority over **Databricks** in data warehouse AI applica..."
original_link: "https://news.smol.ai/issues/24-04-25-ainews-snowflake-arctic-fully-open-10b128x4b-dense-moe-hybrid-llm/"
---

**Snowflake Arctic** is a notable new foundation language model released under Apache 2.0, claiming superiority over **Databricks** in data warehouse AI applications and adopting a mixture-of-experts architecture inspired by **DeepSeekMOE** and **DeepSpeedMOE**. The model employs a 3-stage curriculum training strategy similar to the recent **Phi-3** paper. In AI image and video generation, **Nvidia** introduced the **Align Your Steps** technique improving image quality at low step counts, while **Stable Diffusion 3** and **SD3 Turbo** models were compared for prompt understanding and image quality. **Adobe** launched an AI video upscaling project enhancing blurry videos to HD, though with some high-resolution artifacts. **Apple** released open-source on-device language models with code and training logs, diverging from typical weight-only releases. The **Llama-3-70b** model ties for first place on the LMSYS leaderboard for English queries, and **Phi-3** (4B params) outperforms **GPT-3.5 Turbo** in the banana logic benchmark. Fast inference and quantization of **Llama 3** models were demonstrated on MacBook devices.

[Read original post](https://news.smol.ai/issues/24-04-25-ainews-snowflake-arctic-fully-open-10b128x4b-dense-moe-hybrid-llm/)
