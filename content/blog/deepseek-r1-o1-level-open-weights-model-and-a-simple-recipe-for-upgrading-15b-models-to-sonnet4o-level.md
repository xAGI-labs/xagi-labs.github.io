---
title: "DeepSeek R1: o1-level open weights model and a simple recipe for upgrading 1.5B models to Sonnet/4o level"
date: "2025-01-21T07:50:24.000Z"
description: "**DeepSeek** released **DeepSeek R1**, a significant upgrade over **DeepSeek V3** from just three weeks prior, featuring 8 models including full-size 671B MoE m..."
original_link: "https://news.smol.ai/issues/25-01-20-ainews-deepseek-r1-o1-level-open-weights-model-and-a-simple-recipe-for-upgrading-15b-models-to-sonnet4o-level/"
---

**DeepSeek** released **DeepSeek R1**, a significant upgrade over **DeepSeek V3** from just three weeks prior, featuring 8 models including full-size 671B MoE models and multiple distillations from **Qwen 2.5** and **Llama 3.1/3.3**. The models are MIT licensed, allowing finetuning and distillation. Pricing is notably cheaper than **o1** by 27x-50x. The training process used **GRPO** (reward for correctness and style outcomes) without relying on PRM, MCTS, or reward models, focusing on reasoning improvements through reinforcement learning. Distilled models can run on **Ollama** and show strong capabilities like writing **Manim code**. The release emphasizes advances in **reinforcement-learning**, **fine-tuning**, and **model-distillation** with a novel RL framework from DeepSeekMath.

[Read original post](https://news.smol.ai/issues/25-01-20-ainews-deepseek-r1-o1-level-open-weights-model-and-a-simple-recipe-for-upgrading-15b-models-to-sonnet4o-level/)
