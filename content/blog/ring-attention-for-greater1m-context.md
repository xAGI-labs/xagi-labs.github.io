---
title: "Ring Attention for >1M Context"
date: "2024-02-23T00:51:56.000Z"
description: "**Google Gemini Pro** has sparked renewed interest in long context capabilities. The CUDA MODE Discord is actively working on implementing the **RingAttention**..."
original_link: "https://news.smol.ai/issues/24-02-22-ainews-ring-attention-for-greater1m-context/"
---

**Google Gemini Pro** has sparked renewed interest in long context capabilities. The CUDA MODE Discord is actively working on implementing the **RingAttention** paper by Liu, Zaharia, and Abbeel, including extensions from the World Model RingAttention paper, with available PyTorch and CUDA implementations. TheBloke Discord discussed various topics including **LLM guessing game evaluation**, chatbot UX comparisons between **Nvidia's Chat with RTX** and **Polymind**, challenges in **retrieval-augmented generation (RAG)** integration, VRAM optimization, fine-tuning for character roleplay using **Dynamic Prompt Optimization (DPO)**, and model choices like **deepseek-coder-6.7B-instruct**. There was also discussion on ML workflows on Mac Studio, with preferences for **llama.cpp** over **ollama**, and scaling inference cost-effectively using GPUs like the **4090** on Runpod. LM Studio users face manual update requirements for version **0.2.16**, which includes support for **Gemma models** and bug fixes, especially for MacOS. The Gemma 7B model has had performance issues, while Gemma 2B received positive feedback.

[Read original post](https://news.smol.ai/issues/24-02-22-ainews-ring-attention-for-greater1m-context/)
