---
title: "Pixtral Large (124B) beats Llama 3.2 90B with updated Mistral Large 24.11"
date: "2024-11-19T02:25:23.000Z"
description: "**Mistral** has updated its **Pixtral Large** vision encoder to 1B parameters and released an update to the **123B parameter Mistral Large 24.11** model, though..."
original_link: "https://news.smol.ai/issues/24-11-18-ainews-pixtral-large-124b-beats-llama-32-90b-with-updated-mistral-large-2411/"
---

**Mistral** has updated its **Pixtral Large** vision encoder to 1B parameters and released an update to the **123B parameter Mistral Large 24.11** model, though the update lacks major new features. **Pixtral Large** outperforms **Llama 3.2 90B** on multimodal benchmarks despite having a smaller vision adapter. **Mistral's Le Chat** chatbot received comprehensive feature updates, reflecting a company focus on product and research balance as noted by **Arthur Mensch**. **SambaNova** sponsors inference with their RDUs offering faster AI model processing than GPUs. On Reddit, **vLLM** shows strong concurrency performance on an **RTX 3090** GPU, with quantization challenges noted in **FP8 kv-cache** but better results using **llama.cpp** with **Q8 kv-cache**. Users discuss performance trade-offs between **vLLM**, **exllamav2**, and **TabbyAPI** for different model sizes and batching strategies.

[Read original post](https://news.smol.ai/issues/24-11-18-ainews-pixtral-large-124b-beats-llama-32-90b-with-updated-mistral-large-2411/)
