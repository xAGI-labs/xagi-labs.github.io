---
title: "Llama 3.2: On-device 1B/3B, and Multimodal 11B/90B (with AI2 Molmo kicker)"
date: "2024-09-25T23:54:30.000Z"
description: "**Meta** released **Llama 3.2** with new multimodal versions including **3B** and **20B** vision adapters on a frozen Llama 3.1, showing competitive performance..."
original_link: "https://news.smol.ai/issues/24-09-25-ainews-llama-32-on-device-1b3b-and-multimodal-11b90b-with-ai2-molmo-kicker/"
---

**Meta** released **Llama 3.2** with new multimodal versions including **3B** and **20B** vision adapters on a frozen Llama 3.1, showing competitive performance against **Claude Haiku** and **GPT-4o-mini**. **AI2** launched multimodal **Molmo 72B** and **7B** models outperforming Llama 3.2 in vision tasks. Meta also introduced new **128k-context 1B and 3B models** competing with **Gemma 2** and **Phi 3.5**, with collaborations hinted with **Qualcomm**, **Mediatek**, and **Arm** for on-device AI. The release includes a **9 trillion token count** for Llama 1B and 3B. Partner launches include **Ollama**, **Together AI** offering free 11B model access, and **Fireworks AI**. Additionally, a new **RAG++ course** from **Weights & Biases**, **Cohere**, and **Weaviate** offers systematic evaluation and deployment guidance for retrieval-augmented generation systems based on extensive production experience.

[Read original post](https://news.smol.ai/issues/24-09-25-ainews-llama-32-on-device-1b3b-and-multimodal-11b90b-with-ai2-molmo-kicker/)
