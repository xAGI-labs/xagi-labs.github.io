---
title: "OpenAI Titan XPU: 10GW of self-designed chips with Broadcom"
date: "2025-10-13T05:44:39.000Z"
description: "**OpenAI** is finalizing a custom ASIC chip design to deploy **10GW** of inference compute, complementing existing deals with **NVIDIA** (10GW) and **AMD** (6GW..."
original_link: "https://news.smol.ai/issues/25-10-13-oai-broadcom/"
---

**OpenAI** is finalizing a custom ASIC chip design to deploy **10GW** of inference compute, complementing existing deals with **NVIDIA** (10GW) and **AMD** (6GW). This marks a significant scale-up from OpenAI's current **2GW** compute, aiming for a roadmap of **250GW** total, which is half the energy consumption of the US. Greg from OpenAI highlights the shift of **ChatGPT** from interactive use to always-on ambient agents requiring massive compute, emphasizing the challenge of building chips for billions of users. The in-house ASIC effort was driven by the need for tailored designs after limited success influencing external chip startups. Broadcom's stock surged 10% on the news. Additionally, **InferenceMAX** reports improved ROCm stability and nuanced performance comparisons between AMD MI300X and NVIDIA H100/H200 on **llama-3-70b** FP8 workloads, with RL training infrastructure updates noted.

[Read original post](https://news.smol.ai/issues/25-10-13-oai-broadcom/)
