---
title: "GPT-4o: the new SOTA-EVERYTHING Frontier model (GPT4O version)"
date: "2024-05-13T22:58:05.000Z"
description: "**OpenAI** has released **GPT-4o**, a new **multimodal** model capable of reasoning across text, audio, and video in real time with low latency (~300ms). It fea..."
original_link: "https://news.smol.ai/issues/24-05-13-ainews-gpt-4o-the-new-sota-everything-frontier-model-gpt4o-version/"
---

**OpenAI** has released **GPT-4o**, a new **multimodal** model capable of reasoning across text, audio, and video in real time with low latency (~300ms). It features voice and vision capabilities, improved non-English language performance with an expanded 200k vocabulary tokenizer, and is available to all ChatGPT users including free plans. GPT-4o is half the price and twice as fast as GPT-4-turbo with 5x rate limits. The model supports real-time voice and video input/output and shows strong coding capabilities. The release includes a new desktop app that can read screen and clipboard history, challenging existing desktop agent startups. The announcement was accompanied by demos including image generation and 3D object handling, with OpenAI achieving state-of-the-art performance in ASR and vision tasks. The update was widely discussed on social media, with comparisons to GPT-4T highlighting GPT-4o's speed and versatility. \*"GPT-4o is smart, fast, natively multimodal, and a step towards more natural human-computer interaction"\* and \*"extremely versatile and fun to play with"\*.

[Read original post](https://news.smol.ai/issues/24-05-13-ainews-gpt-4o-the-new-sota-everything-frontier-model-gpt4o-version/)
