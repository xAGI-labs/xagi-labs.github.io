---
title: "Claude Crushes Code - 92% HumanEval and Claude.ai Artifacts"
date: "2024-06-21T07:27:45.000Z"
description: "**Claude 3.5 Sonnet**, released by **Anthropic**, is positioned as a Pareto improvement over Claude 3 Opus, operating at **twice the speed** and costing **one-f..."
original_link: "https://news.smol.ai/issues/24-06-21-ainews-claude-crushes-code-92percent-humaneval-and-claudeai-artifacts/"
---

**Claude 3.5 Sonnet**, released by **Anthropic**, is positioned as a Pareto improvement over Claude 3 Opus, operating at **twice the speed** and costing **one-fifth** as much. It achieves state-of-the-art results on benchmarks like **GPQA, MMLU, and HumanEval**, surpassing even **GPT-4o** and Claude 3 Opus on vision tasks. The model demonstrates significant advances in coding capabilities, passing **64% of test cases** compared to 38% for Claude 3 Opus, and is capable of autonomously fixing pull requests. Anthropic also introduced the **Artifacts** feature, enabling users to interact with AI-generated content such as code snippets and documents in a dynamic workspace, similar to OpenAI's Code Interpreter. This release highlights improvements in performance, cost-efficiency, and coding proficiency, signaling a growing role for LLMs in software development.

[Read original post](https://news.smol.ai/issues/24-06-21-ainews-claude-crushes-code-92percent-humaneval-and-claudeai-artifacts/)
