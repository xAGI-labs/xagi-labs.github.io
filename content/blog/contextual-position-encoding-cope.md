---
title: "Contextual Position Encoding (CoPE)"
date: "2024-05-31T03:11:48.000Z"
description: "**Meta AI** researcher **Jason Weston** introduced **CoPE**, a novel positional encoding method for transformers that incorporates *context* to create learnable..."
original_link: "https://news.smol.ai/issues/24-05-30-ainews-contextual-position-encoding-cope/"
---

**Meta AI** researcher **Jason Weston** introduced **CoPE**, a novel positional encoding method for transformers that incorporates \*context\* to create learnable gates, enabling improved handling of counting and copying tasks and better performance on language modeling and coding. The approach can potentially be extended with external memory for gate calculation. **Google DeepMind** released **Gemini 1.5 Flash** and **Pro** models optimized for fast inference. **Anthropic** announced general availability of tool use for **Claude**, enhancing its ability to orchestrate tools for complex tasks. **Alexandr Wang** launched **SEAL Leaderboards** for private, expert evaluations of frontier models. **Karpathy** reflected on the 4th anniversary of **GPT-3**, emphasizing scaling and practical improvements. **Perplexity AI** launched **Perplexity Pages** to convert research into visually appealing articles, described as an "AI Wikipedia" by **Arav Srinivas**.

[Read original post](https://news.smol.ai/issues/24-05-30-ainews-contextual-position-encoding-cope/)
