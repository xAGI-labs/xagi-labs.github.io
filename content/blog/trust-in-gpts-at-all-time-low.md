---
title: "Trust in GPTs at all time low"
date: "2024-02-02T03:25:24.000Z"
description: "**Discord communities** were analyzed with **21 guilds**, **312 channels**, and **8530 messages** reviewed, saving an estimated **628 minutes** of reading time...."
original_link: "https://news.smol.ai/issues/24-02-01-ainews-trust-in-gpts-at-all-time-low/"
---

**Discord communities** were analyzed with **21 guilds**, **312 channels**, and **8530 messages** reviewed, saving an estimated **628 minutes** of reading time. Discussions highlighted challenges with **GPTs** and the **GPT store**, including critiques of the **knowledge files capability** and context management issues. The **CUDA MODE Discord** was introduced for CUDA coding support. Key conversations in the **TheBloke Discord** covered **Xeon** GPU server cost-effectiveness, **Llama3** and **Mistral Medium** model comparisons, **LLaVA-1.6**'s visual reasoning and OCR capabilities, and the leaked **Miqu** 70B model. Technical topics included fine-tuning **TinyLlama** and **MiquMaid+Euryale** models, and model merging with examples like **Harmony-4x7B-bf16** and **Smaug-34B-v0.1**. The **Nous Research AI Discord** discussed style influence in LLMs, quantization issues, **Bittensor** incentives for AI model improvements, and the identification of **MIQU** as **Mistral Medium**. The release of the **Open Hermes 2.5 dataset** on **Hugging Face** was also announced. \*"Discussions pointed towards the need for better context management in GPTs, contrasting with OpenAI's no-code approach."\*

[Read original post](https://news.smol.ai/issues/24-02-01-ainews-trust-in-gpts-at-all-time-low/)
