---
title: "The Quiet Rise of Claude Code vs Codex"
date: "2025-06-20T05:44:39.000Z"
description: "**Claude Code** is gaining mass adoption, inspiring derivative projects like **OpenCode** and **ccusage**, with discussions ongoing in AI communities. **Mistral..."
original_link: "https://news.smol.ai/issues/25-06-20-claude-code/"
---

**Claude Code** is gaining mass adoption, inspiring derivative projects like **OpenCode** and **ccusage**, with discussions ongoing in AI communities. **Mistral AI** released **Mistral Small 3.2**, a **24B** parameter model update improving instruction following and function calling, available on **Hugging Face** and supported by **vLLM**. Sebastian Raschka implemented **Qwen3 0.6B** from scratch, noting its deeper architecture and memory efficiency compared to **Llama 3 1B**. **Google DeepMind** showcased **Gemini 2.5 Flash-Lite**'s UI code generation from visual context and added video upload support in the **Gemini App**. **Apple**'s new **3B** parameter on-device foundation model was benchmarked, showing slower speed but efficient memory use via **2-bit quantization**, suitable for background tasks. **Google DeepMind** also released **Magenta Real-time**, an **800M** parameter music generation model licensed under **Apache 2.0**, marking Google's 1000th model on **Hugging Face**. **Kuaishou** launched **KLING 2.1**, a new video model accessible via API.

[Read original post](https://news.smol.ai/issues/25-06-20-claude-code/)
