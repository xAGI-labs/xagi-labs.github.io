---
title: "Karpathy emerges from stealth?"
date: "2024-02-21T01:54:38.000Z"
description: "**Andrej Karpathy** released a comprehensive 2-hour tutorial on **tokenization**, detailing techniques up to **GPT-4**'s tokenizer and noting the complexity of ..."
original_link: "https://news.smol.ai/issues/24-02-20-ainews-karpathy-emerges-from-stealth/"
---

**Andrej Karpathy** released a comprehensive 2-hour tutorial on **tokenization**, detailing techniques up to **GPT-4**'s tokenizer and noting the complexity of **Llama 2** tokenization with SentencePiece. Discussions in AI Discord communities covered **model optimization and efficiency**, focusing on **quantization** of models like **Mistral 7B** and **Zephyr-7B** to reduce memory usage for consumer GPUs, including Intel's new weight-only quantization algorithm. Efforts to improve computational efficiency included selective augmentation reducing costs by 57.76% and memory token usage versus kNN for Transformers. Challenges in hardware compatibility and software issues were shared, alongside fine-tuning techniques such as LoRA and model merging. Innovative applications of LLMs in retrieval-augmented generation (RAG), multi-model learning, and meta-reasoning were explored. The community emphasized dataset sharing, open-source releases like SDXL VAE encoded datasets and Audiogen AI codecs, and ethical AI use with censorship and guardrails. Collaboration and resource sharing remain strong in these AI communities.

[Read original post](https://news.smol.ai/issues/24-02-20-ainews-karpathy-emerges-from-stealth/)
