---
title: "Common Corpus: 2T Open Tokens with Provenance"
date: "2024-11-14T01:54:53.000Z"
description: "**Pleais** via **Huggingface** released **Common Corpus**, the largest fully open multilingual dataset with over **2 trillion tokens** including detailed **prov..."
original_link: "https://news.smol.ai/issues/24-11-13-ainews-common-corpus-2t-open-tokens-with-provenance/"
---

**Pleais** via **Huggingface** released **Common Corpus**, the largest fully open multilingual dataset with over **2 trillion tokens** including detailed **provenance information**. They also introduced **OCRonos-Vintage**, a **124M-parameter OCR correction model** that efficiently fixes digitization errors on CPU and GPU, unlocking knowledge from PDFs. On AI tools, **LangChainAI** launched **Prompt Canvas** for collaborative **prompt engineering**, while **DeepSeek** released **JanusFlow 1.3B**, a unified multimodal LLM integrating autoregressive and rectified flow models for enhanced **image understanding** and **generation**. **Alibaba Cloud** announced **Qwen2.5-Coder**, a code-focused LLM with advanced coding capabilities, and **Claude 3.5 Sonnet** was highlighted for superior code generation. Discussions on **quantization challenges** and **scaling laws for precision** by **Tim Dettmers** and others emphasized the impact of low-precision training on model scalability and inference efficiency. \*"Scaling Laws for Precision"\* paper insights and alternative efficiency methods were also noted.

[Read original post](https://news.smol.ai/issues/24-11-13-ainews-common-corpus-2t-open-tokens-with-provenance/)
