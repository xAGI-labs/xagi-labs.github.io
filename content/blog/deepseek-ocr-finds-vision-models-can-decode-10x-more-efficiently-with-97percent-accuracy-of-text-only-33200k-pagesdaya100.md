---
title: "DeepSeek-OCR finds vision models can decode 10x more efficiently with ~97% accuracy of text-only, 33/200k pages/day/A100"
date: "2025-10-20T05:44:39.000Z"
description: "As **ICCV 2025** begins, **DeepSeek** releases a novel **DeepSeek-OCR** 3B MoE vision-language model that compresses long text as visual context with high accur..."
original_link: "https://news.smol.ai/issues/25-10-20-deepseek-ocr/"
---

As **ICCV 2025** begins, **DeepSeek** releases a novel **DeepSeek-OCR** 3B MoE vision-language model that compresses long text as visual context with high accuracy and efficiency, challenging traditional tokenization approaches. The model achieves ~97% decoding precision at <10Ã— compression and processes up to ~33M pages/day on 20 A100-40G nodes, outperforming benchmarks like GOT-OCR2.0. Discussions highlight the potential for unlimited context windows and tokenization-free inputs, with contributions from **@karpathy**, **@teortaxesTex**, and others. In video generation, **google-deepmind**'s **Veo 3.1** leads community benchmarks with advanced precision editing and scene blending, while **Krea** open-sources a 14B autoregressive video model enabling realtime long-form generation at ~11 FPS on a single B200 GPU.

[Read original post](https://news.smol.ai/issues/25-10-20-deepseek-ocr/)
